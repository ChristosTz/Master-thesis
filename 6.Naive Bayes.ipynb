{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3863524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456ea0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_count</th>\n",
       "      <th>proper_noun_count</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>compound</th>\n",
       "      <th>neutral</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.2449</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44868</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>0.580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44869</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44870</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44871</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44872</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44873 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       verb_count  proper_noun_count  emotiveness  compound  neutral  label\n",
       "0               2                  2     0.200000   -0.4939    0.656      0\n",
       "1               1                  3     1.000000    0.3818    0.755      0\n",
       "2               1                  5     0.500000    0.0000    1.000      0\n",
       "3               1                  2     0.200000    0.0000    1.000      0\n",
       "4               2                  1     0.600000    0.2449    0.835      0\n",
       "...           ...                ...          ...       ...      ...    ...\n",
       "44868           1                  3     0.666667   -0.3818    0.580      1\n",
       "44869           1                  3     0.000000    0.5267    0.764      1\n",
       "44870           1                  3     0.500000    0.4404    0.838      1\n",
       "44871           3                  2     0.250000    0.0000    1.000      1\n",
       "44872           1                  3     0.600000    0.0000    1.000      1\n",
       "\n",
       "[44873 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('selected_features.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fa261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (26923, 5) \n",
      "\n",
      "X_test shape: (8975, 5) \n",
      "\n",
      "X_val shape: (8975, 5) \n",
      "\n",
      "y_train shape: (26923,)\n",
      "\n",
      "y_test shape: (8975,)\n",
      "\n",
      "y_val shape: (8975,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac = 1, random_state=42)\n",
    "X = df.loc[:,['verb_count',\n",
    " 'proper_noun_count',\n",
    " 'emotiveness',\n",
    " 'compound',\n",
    " 'neutral']]\n",
    "y=df.label\n",
    "\n",
    "#Split X & y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=0.2, shuffle = True, random_state = 8)\n",
    "#Split remaining train into train and  validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "\n",
    "print(\"X_train shape: {} \\n\".format(X_train.shape))\n",
    "print(\"X_test shape: {} \\n\" .format(X_test.shape))\n",
    "print(\"X_val shape: {} \\n\".format(X_val.shape))\n",
    "print(\"y_train shape: {}\\n\".format(y_train.shape))\n",
    "print(\"y_test shape: {}\\n\".format(y_test.shape))\n",
    "print(\"y_val shape: {}\\n\".format(y_val.shape))\n",
    "\n",
    "\n",
    "# Scale the featrues, you are fitting and transforming the train features but not the test/val. Testing data must remain unseen by the model. If you fit the testing data then your model learned on the testing data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.transform(X_val)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9732e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.78      4213\n",
      "           1       0.86      0.70      0.77      4762\n",
      "\n",
      "    accuracy                           0.78      8975\n",
      "   macro avg       0.79      0.78      0.78      8975\n",
      "weighted avg       0.79      0.78      0.78      8975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_val)\n",
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b5f805c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 14 candidates, totalling 420 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.78      4213\n",
      "           1       0.86      0.70      0.77      4762\n",
      "\n",
      "    accuracy                           0.78      8975\n",
      "   macro avg       0.79      0.78      0.78      8975\n",
      "weighted avg       0.79      0.78      0.78      8975\n",
      "\n",
      "6.66 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "\n",
    "gnb = GaussianNB()\n",
    "parameters = {'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gridCV = GridSearchCV(gnb, parameters, cv=cv, verbose=1, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "gridCV.fit(X_train, y_train)\n",
    "y_pred = gridCV.predict(X_val)\n",
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "066e10ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 14 candidates, totalling 420 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.78      4213\n",
      "           1       0.86      0.70      0.77      4762\n",
      "\n",
      "    accuracy                           0.78      8975\n",
      "   macro avg       0.79      0.78      0.78      8975\n",
      "weighted avg       0.79      0.78      0.78      8975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Repeat with no timer\n",
    "\n",
    "gnb = GaussianNB()\n",
    "parameters = {'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gridCV = GridSearchCV(gnb, parameters, cv=cv, verbose=1, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "gridCV.fit(X_train, y_train)\n",
    "y_pred = gridCV.predict(X_val)\n",
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c909ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pd.read_csv('political news for cv')\n",
    "gp = pd.read_csv('gossip news for cv')\n",
    "\n",
    "X_gp = gp.loc[:,['verb_count',\n",
    " 'proper_noun_count',\n",
    " 'emotiveness',\n",
    " 'compound',\n",
    " 'neutral']]\n",
    "y_gp = gp.label\n",
    "\n",
    "X_pl = pl.loc[:,['verb_count',\n",
    " 'proper_noun_count',\n",
    " 'emotiveness',\n",
    " 'compound',\n",
    " 'neutral']]\n",
    "y_pl = pl.label\n",
    "\n",
    "\n",
    "X_gp = sc.transform(X_gp)\n",
    "X_pl = sc.transform(X_pl)\n",
    "\n",
    "y_pred_pl = gridCV.predict(X_pl)\n",
    "y_pred_gp = gridCV.predict(X_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0061e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.70       429\n",
      "           1       0.66      0.63      0.64       381\n",
      "\n",
      "    accuracy                           0.67       810\n",
      "   macro avg       0.67      0.67      0.67       810\n",
      "weighted avg       0.67      0.67      0.67       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_pl, y_pl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e5af0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73     14227\n",
      "           1       0.42      0.29      0.34      7395\n",
      "\n",
      "    accuracy                           0.62     21622\n",
      "   macro avg       0.55      0.54      0.54     21622\n",
      "weighted avg       0.59      0.62      0.60     21622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_gp, y_gp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a98985b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3650  563]\n",
      " [1437 3325]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b576b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
